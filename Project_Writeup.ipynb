{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Classification** \n",
    "\n",
    "\n",
    "## Deep Learning\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Classification Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/visualization.jpg \"Visualization\"\n",
    "[image2]: ./examples/normalized.png \"Normalized\"\n",
    "[image3]: ./examples/test_images.png \"Test Images\"\n",
    "[image4]: ./examples/max_distribution.png \"Distribution\"\n",
    "[image5]: ./examples/original.png \"Original\"\n",
    "[image6]: ./examples/grayscale.png \"Grayscale\"\n",
    "[image7]: ./examples/predicted.png \"Predicted\"\n",
    "[image8]: ./examples/visualize_layer1.png \"Visualize Layer\"\n",
    "\n",
    "\n",
    "You're reading it! and here is a link to my [project code](https://github.com/nehbehl/CarND-Traffic-Sign-Classifier-Project-master/blob/main/Traffic_Sign_Classifier.ipynb)\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "I used the pandas library and numpy methods to calculate summary statistics of the traffic\n",
    "signs data set:\n",
    "\n",
    "* The size of training set is 34799\n",
    "* The size of the validation set is 4410\n",
    "* The size of test set is 12630\n",
    "* The shape of a traffic sign image is (32, 32, 3)\n",
    "* The number of unique classes/labels in the data set is 43\n",
    "\n",
    "#### Exploratory visualization of the dataset.\n",
    "\n",
    "Here is an exploratory visualization of the data set. It is a bar chart showing the distribution of training dataset amongst different classes of sign names. Maximum distribution was given to Speed limit (50km/h) sign \n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "Distribution in training dataset:  2010\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "\n",
    "### Design and Test a Model Architecture\n",
    "\n",
    "#### 1. Pre-processing images in training dataset\n",
    "\n",
    "As a first step, I decided to convert the images to grayscale so as to reduce the complexity.\n",
    "\n",
    "Here is an example of a traffic sign image before and after grayscaling.\n",
    "\n",
    "![alt text][image5]\n",
    "![alt text][image6]\n",
    "\n",
    "\n",
    "Further, I normalized the image to get better accuracy when training my model. Here is an example of above grayscaled image after applying normalization.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "\n",
    "#### 2. Model Architecture\n",
    "\n",
    "My final model consisted of the following layers and activation functions:\n",
    "\n",
    "| Layer                 | Description                                            | Number of parameters     |\n",
    "| :--------------------:| :----------------------------------------------------: | :-----------------------:|\n",
    "| Input         \t\t| 32x32x1 Normalized image   \t\t\t\t\t         |                          |\n",
    "| Convolution layer1   \t| 1x1 stride, valid padding, 5X5 filter, outputs 28X28X6 |   (5x5x1+1)X6 = 156      |\n",
    "| RELU                                                                                                      |\n",
    "| Max pooling\t      \t| 2x2 stride, 2X2 kernel size  outputs 14x14x6 \t         |                          |\n",
    "| Convolution layer2    | 1x1 stride, valid padding, 5X5 filter, outputs 10X10X16|   (5x5x6+1)X16 = 2416    |\n",
    "| RELU  \t\t\t\t           \t\t\t\t\t\t\t\t                                            |\n",
    "| Max pooling\t\t\t| 2x2 stride, 2X2 kernelsize  outputs 5x5x16             |                          |\n",
    "| Flatten\t\t\t\t| Converting output to vector        \t\t\t         |                          |\n",
    "| Fully Connected layer1|  Input = 400, Output = 120   \t\t\t\t\t         |  (400+1)X120 = 48120     |\n",
    "| RELU  \t\t\t\t    \t\t\t\t\t\t\t\t\t\t\t                                    |\n",
    "| Fully Connected layer2|  Input = 120, Output = 84   \t\t\t\t\t         |  (120+1)X84 = 10164      |\n",
    "| RELU  \t\t\t\t    \t\t\t\t\t\t\t\t\t\t          \t                            |\n",
    "| Fully Connected layer3|  Input = 84, Output = 43   \t\t\t\t\t         |  (84+1)43 = 3655         |\n",
    " \n",
    "\n",
    "\n",
    "#### 3. Training the Model\n",
    "\n",
    "To train the model, I used a high epoch size of 50 to ensure that my model gets trained well and batch size of 10. I used a learning rate of 0.001 as it helped to get better training accuracy. \n",
    "\n",
    "#### 4. Model results\n",
    "\n",
    "My model is based on LeNet architecture and I had earlier used it to classify the MNIST dataset. I found out that this architecture works well for traffic sign classification as well with higher epoch values.\n",
    "\n",
    "My final model results were:\n",
    "* training set accuracy of 95%\n",
    "* validation set accuracy of 95% \n",
    "* test set accuracy of 100%\n",
    " \n",
    "\n",
    "###  Test Model\n",
    "\n",
    "#### 1. Test images\n",
    "\n",
    "Here are five German traffic signs that I used to test my model. The specific quality of these images is that some of them are straightforward enough to be easily predictable and should give high accuracy by model and few are typical and are hard to predict.\n",

    "\n",
    "![alt text][image3]\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Model prediction\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "| Image\t\t\t                       |     Prediction\t        \t\t\t\t   | \n",
    "|:-----------------------------------: |:-----------------------------------------:| \n",
    "| Vehicles over 3.5 ton prohibited     | Vehicles over 3.5 ton prohibited          | \n",
    "| Speed Limit (30km/h)                 | Speed Limit (30km/h)   \t\t\t\t   |\n",
    "| Keep right   \t\t\t\t           | Keep right \t\t\t\t\t\t\t   |\n",
    "| Turn right ahead           \t       | Turn right ahead\t\t\t \t\t\t   |\n",
    "| Right-of-way at the next intersection| Right-of-way at the next intersection     |\n",
    "\n",
    "\n",
    "The model was able to correctly guess 5 of the 5 traffic signs, which gives an accuracy of 100%. This compares favorably to the accuracy on the training \n",
    "\n",
    "#### 3. Softmax Probabilities\n",
    "\n",
    "The code for making predictions on my final model is located in the section 'Output Top 5 Softmax Probabilities' of my 'Traffic_Sign_Classifier' notebook.\n",
    "\n",
    "The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 1.0         \t\t\t| Vehicles over 3.5 ton prohibited  \t\t\t| \n",
    "| 1.0     \t\t\t\t| Speed Limit (30km/h)   \t\t\t\t\t\t|\n",
    "| 1.0\t\t\t\t\t| Keep right\t\t\t\t\t\t\t\t\t|\n",
    "| 1.0\t      \t\t\t| Turn right ahead\t\t\t\t \t\t\t\t|\n",
    "| 1.0\t\t\t\t    | Right-of-way at the next intersection  \t\t|\n",
    "\n",
    "\n",
    "### Visualizing output of convolutional layer 1\n",
    "\n",
    "Here are the feature maps generated when visualizing the convolutional layer 1 output:\n",
    "\n",
    "![alt text][image8]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
